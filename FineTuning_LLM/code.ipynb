{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM,AutoModel\n",
    "import  torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anconda\\envs\\llm\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./model/gpt2_chinese\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./model/gpt2_chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'world', '!']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_txt ='hello world!'\n",
    "\n",
    "tokenizer.tokenize(input_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 8701, 8572, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(input_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 8701, 8572, 106, 102]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_txt=tokenizer.encode(input_txt)  # ç¼–ç è¾“å…¥æ–‡æœ¬\n",
    "en_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] hello world! [SEP]'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_txt=tokenizer.decode(en_txt)  # è§£ç ç¼–ç æ–‡æœ¬\n",
    "de_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world!====>{'input_ids': [101, 8701, 8572, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}\n",
      "hello world!====>['hello', 'world', '!']\n",
      "[1,2,3,4,5]====>{'input_ids': [101, 138, 122, 117, 123, 117, 124, 117, 125, 117, 126, 140, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "[1,2,3,4,5]====>['[', '1', ',', '2', ',', '3', ',', '4', ',', '5', ']']\n",
      "12345====>{'input_ids': [101, 9700, 102], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}\n",
      "12345====>['12345']\n",
      "0.123====>{'input_ids': [101, 121, 119, 8604, 102], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}\n",
      "0.123====>['0', '.', '123']\n",
      "This is a  test demo====>{'input_ids': [101, 100, 8310, 143, 10060, 10828, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n",
      "This is a  test demo====>['[UNK]', 'is', 'a', 'test', 'demo']\n"
     ]
    }
   ],
   "source": [
    "txts =['hello world!', '[1,2,3,4,5]', \n",
    "       '12345', \n",
    "       '0.123', \n",
    "       'This is a  test demo']\n",
    "\n",
    "for i  in txts:\n",
    "    print(f'{i}====>{tokenizer(i)}')\n",
    "    print(f'{i}====>{tokenizer.tokenize(i)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  8701,  8572,   106,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,   138,   122,   117,   123,   117,   124,   117,   125,   117,\n",
       "           126,   140,   102],\n",
       "        [  101,  9700,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,   121,   119,  8604,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,   100,  8310,   143, 10060, 10828,   102,     0,     0,     0,\n",
       "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "tokenizer(txts, max_length=2,padding='longest',return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  torch.utils.data import  Dataset,DataLoader\n",
    "\n",
    "class  MyDataset1(Dataset):\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def __len__(self):\n",
    "        return  len(self.data)\n",
    "    def  __getitem__(self,index):\n",
    "        return  tokenizer(self.data[index],return_tensors='pt',padding='longest')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  torch.utils.data import  Dataset,DataLoader\n",
    "\n",
    "class  MyDataset2(Dataset):\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "    def __len__(self):\n",
    "        return  len(self.data)\n",
    "    def  __getitem__(self,index):\n",
    "        return  self.data[index]\n",
    "def collate_fn(batch):\n",
    "    tokenized =tokenizer(batch,return_tensors='pt',padding='longest')\n",
    "    return  dict(labels=tokenized['input_ids'],\n",
    "        input_ids =tokenized['input_ids'],\n",
    "                 attention_mask=tokenized['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 101, 8701, 8572,  106,  102]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDataset=MyDataset1(data=txts)\n",
    "trainloader=DataLoader(dataset=myDataset,batch_size=1)\n",
    "next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor([[ 101, 8701, 8572,  106,  102]]),\n",
       " 'input_ids': tensor([[ 101, 8701, 8572,  106,  102]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDataset=MyDataset2(data=txts)\n",
    "trainloader=DataLoader(dataset=myDataset,batch_size=1,collate_fn=collate_fn)\n",
    "next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(21129, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=21129, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input =torch.randint(0,21129,(1,1000))\n",
    "print(test_input.shape)\n",
    "model.transformer.wte(test_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anconda\\envs\\llm\\lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1.4285, 'train_samples_per_second': 3.5, 'train_steps_per_second': 0.7, 'train_loss': 13.096346855163574, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "train_arags = TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    output_dir=\"./output\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_eval_batch_size=4,\n",
    "    do_eval=False,\n",
    "    evaluation_strategy='no',\n",
    "    optim='adafactor',\n",
    "    logging_steps=10,\n",
    "    report_to='none',\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_arags,\n",
    "    train_dataset=myDataset,\n",
    "    data_collator=collate_fn,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model('output')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anconda\\envs\\llm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,032,192 || all params: 103,101,696 || trainable%: 1.0011\n"
     ]
    }
   ],
   "source": [
    "from  transformers import BitsAndBytesConfig\n",
    "from peft import get_peft_model, LoraConfig,prepare_model_for_kbit_training\n",
    "import torch\n",
    "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path ='./model/gpt2_chinese'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, quantization_config=bnb_config, \n",
    "                                             device_map=\"auto\")\n",
    "\n",
    "lora_config = LoraConfig(r=16,lora_alpha=32,target_modules=[\"c_proj\"],\n",
    "                        lora_dropout=0.05,\n",
    "                        bias=\"none\",\n",
    "                        task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 107, which is longer than the specified 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç¨‹ä¸äº‰å‘ç°ä¸ç®¡æ˜¯å¸ˆå”ï¼Œæˆ–è€…æ˜¯å¸ˆå…„ä»¬æ²¡æœ‰å¿…è¦çš„æƒ…å†µä¸‹éƒ½æ˜¯æ²‰é»˜å¯¡è¨€ï¼Œä¸€å¥è¯ä¹Ÿä¸è¯´ï¼Œå„è‡ªç›˜è†è€Œåï¼Œé—­ç›®å…»ç¥ã€‚\n",
      "â€œè¿™åˆ°åº•æ˜¯å› ä¸ºå¸ˆå”åœ¨åœºï¼Œå¸ˆå…„ä»¬ä¸æ•¢æ”¾è‚†ï¼Œè¿˜æ˜¯......ï¼Ÿâ€\n",
      "ç¨‹ä¸äº‰å‘ç°ä¸ç®¡æ˜¯å¸ˆå”ï¼Œæˆ–è€…æ˜¯å¸ˆå…„ä»¬æ²¡æœ‰å¿…è¦çš„æƒ…å†µä¸‹éƒ½æ˜¯æ²‰é»˜å¯¡è¨€ï¼Œä¸€å¥è¯ä¹Ÿä¸è¯´ï¼Œå„è‡ªç›˜è†è€Œåï¼Œé—­ç›®å…»ç¥ã€‚\n",
      "â€œè¿™åˆ°åº•æ˜¯å› ä¸ºå¸ˆå”åœ¨åœºï¼Œå¸ˆå…„ä»¬ä¸æ•¢æ”¾è‚†ï¼Œè¿˜æ˜¯......ï¼Ÿâ€\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.vectorstores import Chroma\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore') \n",
    " \n",
    "filepath = 'data/novel.txt'\n",
    "raw_documents = TextLoader(filepath, encoding='utf8').load()\n",
    " \n",
    "# æŒ‰è¡Œåˆ†å‰²å—\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    separator=\"\\n\",\n",
    "    length_function=len,\n",
    "    is_separator_regex=True,\n",
    ")\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "# åŠ è½½æœ¬åœ° embedding æ¨¡å‹\n",
    "embedding = HuggingFaceEmbeddings(model_name='./model/hub/AI-ModelScope/bge-small-zh-v1___5')\n",
    "# åˆ›å»ºå‘é‡æ•°æ®åº“\n",
    "db = Chroma.from_documents(documents, embedding, persist_directory=r\"./chroma/\")\n",
    "db.persist()  # ç¡®ä¿åµŒå…¥è¢«å†™å…¥ç£ç›˜\n",
    "'''\n",
    "å¦‚æœå·²ç»åˆ›å»ºå¥½äº†ï¼Œå¯ä»¥ç›´æ¥è¯»å–\n",
    "db = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n",
    "'''\n",
    " \n",
    "# ç›´æ¥ä¼ å…¥æ–‡æœ¬\n",
    "query = \"ç¨‹ä¸äº‰æœ‰äº›å¥½ç¬‘çš„åŸå› \"\n",
    "docs = db.similarity_search(query, k=3)\n",
    "# docs = db.similarity_search_with_score(query, k=3)  # å¸¦åˆ†æ•°çš„\n",
    "print(docs[0].page_content)\n",
    " \n",
    "# ä¼ å…¥å‘é‡å»æœç´¢\n",
    "embedding_vector = embedding.embed_query(query)\n",
    "docs = db.similarity_search_by_vector(embedding_vector, k=3)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={}, page_content='è¯¸å¤©ç‰ç¢Ÿä¹‹ä¸»ï¼šç¨‹ä¸äº‰\\n'), Document(metadata={}, page_content='è¯¸å¤©ç‰ç¢Ÿä¹‹ä¸»ï¼šç¨‹ä¸äº‰\\n'), Document(metadata={}, page_content='è¯¸å¤©ç‰ç¢Ÿä¹‹ä¸»ï¼šç¨‹ä¸äº‰\\n'), Document(metadata={}, page_content='è¯¸å¤©ç‰ç¢Ÿä¹‹ä¸»ï¼šç¨‹ä¸äº‰\\n')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import TFIDFRetriever\n",
    "with open('data/novel.txt', encoding='utf8') as f:\n",
    "    lst = f.readlines()\n",
    "retriever = TFIDFRetriever.from_texts(lst)\n",
    "result = retriever.get_relevant_documents(\"ç¨‹ä¸äº‰\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 107, which is longer than the specified 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç¨‹ä¸äº‰å‘ç°ä¸ç®¡æ˜¯å¸ˆå”ï¼Œæˆ–è€…æ˜¯å¸ˆå…„ä»¬æ²¡æœ‰å¿…è¦çš„æƒ…å†µä¸‹éƒ½æ˜¯æ²‰é»˜å¯¡è¨€ï¼Œä¸€å¥è¯ä¹Ÿä¸è¯´ï¼Œå„è‡ªç›˜è†è€Œåï¼Œé—­ç›®å…»ç¥ã€‚\n",
      "â€œè¿™åˆ°åº•æ˜¯å› ä¸ºå¸ˆå”åœ¨åœºï¼Œå¸ˆå…„ä»¬ä¸æ•¢æ”¾è‚†ï¼Œè¿˜æ˜¯......ï¼Ÿâ€\n",
      "ç¨‹ä¸äº‰å‘ç°ä¸ç®¡æ˜¯å¸ˆå”ï¼Œæˆ–è€…æ˜¯å¸ˆå…„ä»¬æ²¡æœ‰å¿…è¦çš„æƒ…å†µä¸‹éƒ½æ˜¯æ²‰é»˜å¯¡è¨€ï¼Œä¸€å¥è¯ä¹Ÿä¸è¯´ï¼Œå„è‡ªç›˜è†è€Œåï¼Œé—­ç›®å…»ç¥ã€‚\n",
      "â€œè¿™åˆ°åº•æ˜¯å› ä¸ºå¸ˆå”åœ¨åœºï¼Œå¸ˆå…„ä»¬ä¸æ•¢æ”¾è‚†ï¼Œè¿˜æ˜¯......ï¼Ÿâ€\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.vectorstores import Chroma\n",
    " \n",
    " \n",
    "filepath = 'data/novel.txt'\n",
    "raw_documents = TextLoader(filepath, encoding='utf8').load()\n",
    " \n",
    "# æŒ‰è¡Œåˆ†å‰²å—\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    separator=\"\\n\",\n",
    "    length_function=len,\n",
    "    is_separator_regex=True,\n",
    ")\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "# åŠ è½½æœ¬åœ° embedding æ¨¡å‹\n",
    "embedding = HuggingFaceEmbeddings(model_name='./model/hub/AI-ModelScope/bge-small-zh-v1___5')\n",
    "# åˆ›å»ºå‘é‡æ•°æ®åº“\n",
    "db = FAISS.from_documents(documents, embedding)\n",
    "# ä¿å­˜\n",
    "db.save_local(\"./faiss_index\")\n",
    "'''\n",
    "å¦‚æœå·²ç»åˆ›å»ºå¥½äº†ï¼Œå¯ä»¥ç›´æ¥è¯»å–\n",
    "db = FAISS.load_local(\"./faiss_index\", embeddings)\n",
    "'''\n",
    " \n",
    "# ç›´æ¥ä¼ å…¥æ–‡æœ¬\n",
    "query = \"ç¨‹ä¸äº‰æœ‰äº›å¥½ç¬‘çš„åŸå› \"\n",
    "docs = db.similarity_search(query, k=3)\n",
    "# docs = db.similarity_search_with_score(query, k=3)  # å¸¦åˆ†æ•°çš„\n",
    "print(docs[0].page_content)\n",
    " \n",
    "# ä¼ å…¥å‘é‡å»æœç´¢\n",
    "embedding_vector = embedding.embed_query(query)\n",
    "docs = db.similarity_search_by_vector(embedding_vector, k=3)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000017E9D0EFA60>, search_type='mmr', search_kwargs={'k': 30})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={'k': 30})  # æ„å»ºæ£€ç´¢å™¨\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db._co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "\n",
    "    api_key=\"AIzaSyAND9Q0o9s3mRTYcFLLocFTzZExypVsEXE\",\n",
    "\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰å¹¶éå•ä¸€æŠ€æœ¯ï¼Œè€Œæ˜¯ä¸€ç»„æ—¨åœ¨æ¨¡ä»¿äººç±»æ™ºèƒ½çš„æŠ€æœ¯å’Œç®—æ³•çš„é›†åˆã€‚å…¶å·¥ä½œæ–¹å¼å–å†³äºå…·ä½“ç±»å‹ï¼Œä½†ä¸€èˆ¬è€Œè¨€ï¼ŒAI ç³»ç»Ÿä¾é ä»¥ä¸‹å‡ ä¸ªå…³é”®è¦ç´ ï¼š\\n\\n**1. æ•°æ®:** AI ç³»ç»Ÿä¾èµ–å¤§é‡æ•°æ®è¿›è¡Œå­¦ä¹ ã€‚è¿™äº›æ•°æ®å¯ä»¥æ˜¯å›¾åƒã€æ–‡æœ¬ã€éŸ³é¢‘ã€è§†é¢‘æˆ–ä»»ä½•å…¶ä»–å½¢å¼çš„æ•°å­—ä¿¡æ¯ã€‚æ•°æ®çš„è´¨é‡å’Œæ•°é‡ç›´æ¥å½±å“ AI ç³»ç»Ÿçš„æ€§èƒ½ã€‚  æ•°æ®è¶Šå¤šï¼Œæ¨¡å‹é€šå¸¸è¶Šå‡†ç¡®å’Œå¼ºå¤§ã€‚\\n\\n**2. ç®—æ³•:** ç®—æ³•æ˜¯ AI ç³»ç»Ÿçš„æ ¸å¿ƒï¼Œå®ƒä»¬æ˜¯ä¸€ç»„æŒ‡ä»¤ï¼Œå‘Šè¯‰è®¡ç®—æœºå¦‚ä½•å¤„ç†æ•°æ®å¹¶ä»ä¸­å­¦ä¹ ã€‚ä¸åŒç±»å‹çš„ AI ä½¿ç”¨ä¸åŒçš„ç®—æ³•ï¼Œä¾‹å¦‚ï¼š\\n\\n* **æœºå™¨å­¦ä¹  (ML):**  ML ç®—æ³•å…è®¸è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼ï¼Œè€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚  è¿™åŒ…æ‹¬ï¼š\\n    * **ç›‘ç£å­¦ä¹ :**  ç®—æ³•ä½¿ç”¨æ ‡è®°æ•°æ®ï¼ˆå³å·²çŸ¥è¾“å…¥å’Œè¾“å‡ºï¼‰è¿›è¡Œè®­ç»ƒï¼Œå­¦ä¹ å°†è¾“å…¥æ˜ å°„åˆ°è¾“å‡ºã€‚ä¾‹å¦‚ï¼Œè®­ç»ƒä¸€ä¸ªè¯†åˆ«çŒ«çš„å›¾åƒçš„ç³»ç»Ÿï¼Œéœ€è¦æä¾›å¤§é‡æ ‡è®°ä¸ºâ€œçŒ«â€çš„å›¾åƒã€‚\\n    * **æ— ç›‘ç£å­¦ä¹ :**  ç®—æ³•ä½¿ç”¨æœªæ ‡è®°çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå­¦ä¹ æ•°æ®ä¸­çš„å†…åœ¨ç»“æ„å’Œæ¨¡å¼ã€‚ä¾‹å¦‚ï¼Œå°†å®¢æˆ·ç¾¤åˆ†æˆä¸åŒçš„ç»†åˆ†å¸‚åœºã€‚\\n    * **å¼ºåŒ–å­¦ä¹ :**  ç®—æ³•é€šè¿‡ä¸ç¯å¢ƒäº¤äº’è¿›è¡Œå­¦ä¹ ï¼Œå¹¶æ ¹æ®å…¶è¡Œä¸ºè·å¾—å¥–åŠ±æˆ–æƒ©ç½šã€‚ä¾‹å¦‚ï¼Œè®­ç»ƒä¸€ä¸ªç©æ¸¸æˆçš„ AI ç³»ç»Ÿã€‚\\n\\n* **æ·±åº¦å­¦ä¹  (DL):**  æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œä½¿ç”¨äººå·¥ç¥ç»ç½‘ç»œï¼ˆANNï¼‰è¿›è¡Œå­¦ä¹ ã€‚ANN å…·æœ‰å¤šä¸ªå±‚ï¼Œå…è®¸å®ƒä»¬å¤„ç†æ›´å¤æ‚çš„æ•°æ®å’Œæ¨¡å¼ã€‚ä¾‹å¦‚ï¼Œç”¨äºå›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œè¯­éŸ³è¯†åˆ«ç­‰ä»»åŠ¡ã€‚\\n\\n* **è‡ªç„¶è¯­è¨€å¤„ç† (NLP):**  NLP å…è®¸è®¡ç®—æœºç†è§£ã€è§£é‡Šå’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚è¿™åŒ…æ‹¬è¯­éŸ³è¯†åˆ«ã€æœºå™¨ç¿»è¯‘å’Œæƒ…æ„Ÿåˆ†æç­‰ä»»åŠ¡ã€‚\\n\\n* **è®¡ç®—æœºè§†è§‰:**  è®¡ç®—æœºè§†è§‰å…è®¸è®¡ç®—æœºâ€œçœ‹åˆ°â€å’Œè§£é‡Šå›¾åƒå’Œè§†é¢‘ã€‚è¿™åŒ…æ‹¬å¯¹è±¡è¯†åˆ«ã€å›¾åƒåˆ†ç±»å’Œå›¾åƒåˆ†å‰²ç­‰ä»»åŠ¡ã€‚\\n\\n**3. æ¨¡å‹:**  ç®—æ³•å¤„ç†æ•°æ®åï¼Œä¼šåˆ›å»ºä¸€ä¸ªæ¨¡å‹ã€‚è¯¥æ¨¡å‹æ˜¯ä¸€ä¸ªæ•°å­¦è¡¨ç¤ºï¼Œæ•æ‰æ•°æ®ä¸­çš„æ¨¡å¼å’Œå…³ç³»ã€‚æ¨¡å‹ç”¨äºå¯¹æ–°æ•°æ®è¿›è¡Œé¢„æµ‹æˆ–åšå‡ºå†³ç­–ã€‚\\n\\n**4. è®­ç»ƒ:**  è®­ç»ƒæ˜¯æŒ‡ä½¿ç”¨æ•°æ®æ¥è°ƒæ•´æ¨¡å‹å‚æ•°çš„è¿‡ç¨‹ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°é¢„æµ‹æˆ–åšå‡ºå†³ç­–ã€‚è¿™é€šå¸¸æ˜¯ä¸€ä¸ªè¿­ä»£è¿‡ç¨‹ï¼Œéœ€è¦å¤šæ¬¡è°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œç›´åˆ°å…¶è¾¾åˆ°é¢„æœŸçš„æ€§èƒ½æ°´å¹³ã€‚\\n\\n**ç®€è€Œè¨€ä¹‹ï¼ŒAI çš„å·¥ä½œæµç¨‹å¤§è‡´å¦‚ä¸‹ï¼š**\\n\\n1. **æ”¶é›†å’Œå‡†å¤‡æ•°æ®:** æ”¶é›†å¤§é‡ç›¸å…³æ•°æ®å¹¶è¿›è¡Œæ¸…æ´—å’Œé¢„å¤„ç†ã€‚\\n2. **é€‰æ‹©ç®—æ³•:** é€‰æ‹©åˆé€‚çš„ç®—æ³•æ¥å¤„ç†æ•°æ®å¹¶åˆ›å»ºæ¨¡å‹ã€‚\\n3. **è®­ç»ƒæ¨¡å‹:** ä½¿ç”¨æ•°æ®æ¥è®­ç»ƒæ¨¡å‹ï¼Œè°ƒæ•´æ¨¡å‹å‚æ•°ä½¿å…¶èƒ½å¤Ÿå‡†ç¡®åœ°æ‰§è¡Œä»»åŠ¡ã€‚\\n4. **è¯„ä¼°æ¨¡å‹:**  è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶æ ¹æ®éœ€è¦è¿›è¡Œè°ƒæ•´ã€‚\\n5. **éƒ¨ç½²æ¨¡å‹:** å°†è®­ç»ƒå¥½çš„æ¨¡å‹éƒ¨ç½²åˆ°å®é™…åº”ç”¨ä¸­ã€‚\\n\\n\\néœ€è¦æ³¨æ„çš„æ˜¯ï¼Œç›®å‰å¤§éƒ¨åˆ† AI ç³»ç»Ÿéƒ½æ˜¯ç‹­ä¹‰äººå·¥æ™ºèƒ½ (Narrow AI)ï¼Œå®ƒä»¬åªèƒ½åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œè€Œæ— æ³•åƒäººç±»ä¸€æ ·å…·æœ‰æ™®éçš„æ™ºèƒ½ã€‚  é€šç”¨äººå·¥æ™ºèƒ½ (AGI) ä»ç„¶æ˜¯ä¸€ä¸ªç ”ç©¶ç›®æ ‡ã€‚\\n', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    n=1,\n",
    "    messages=[\n",
    "\n",
    "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚\"},\n",
    "\n",
    "        {\n",
    "\n",
    "            \"role\": \"user\",\n",
    "\n",
    "            \"content\": \"ç»™æˆ‘è§£é‡Šä¸€ä¸‹ AI æ˜¯å¦‚ä½•å·¥ä½œçš„\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print (response.choices [0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.010790561325848103, 0.03776538744568825, 0.0071558100171387196, 0.018407689407467842, 0.0523773729801178, 0.03344248980283737, 0.05653980001807213, -0.02108611911535263, 0.035850170999765396, 0.006577409338206053, -0.048622410744428635, 0.03038099594414234, 0.02788544073700905, -0.05758237466216087, -0.010874307714402676, -0.08296309411525726, 0.00896658655256033, -0.009481456130743027, -0.07354788482189178, 0.016750676557421684, -0.004255956970155239, 0.009940783493220806, 0.012476769275963306, 0.006542762275785208, -0.0080301184207201, -0.03046625852584839, 0.003932633902877569, 0.009038825519382954, 0.001194568583741784, -0.022764796391129494, 0.00279880384914577, 0.05642271786928177, 0.03560832515358925, -0.007082000840455294, 0.03799967095255852, 0.02858397364616394, -0.01719231903553009, 0.07472323626279831, 0.023688290268182755, -0.12232840061187744, -0.05243860185146332, -0.0027913018129765987, -0.02130924165248871, 0.021113833412528038, -0.0174113679677248, 0.020022055134177208, 0.02666529454290867, 0.008026338182389736, -0.07210732996463776, 0.03080654889345169, 0.02032185159623623, -0.038461606949567795, -0.029667813330888748, 0.02107101120054722, -0.048595208674669266, 0.012965146452188492, -0.03305262327194214, -0.019531548023223877, 0.08607059717178345, 0.031809523701667786, -0.09515221416950226, 0.025045404210686684, -0.061858881264925, -0.03744138777256012, 0.007257566787302494, -0.009502404369413853, -0.028705185279250145, -0.022047009319067, -0.04186929017305374, -0.014036929234862328, 0.009485803544521332, 0.016301674768328667, -0.044994741678237915, -0.04001963138580322, 0.003102291142567992, -0.013224958442151546, -0.0012947404757142067, -0.03276975825428963, 0.014933011494576931, 0.04756515473127365, -0.06265918910503387, 0.03932344168424606, 0.04009755700826645, 0.07913912832736969, 0.0051198601722717285, 0.0053806365467607975, 0.0493595190346241, -0.05009850859642029, -0.08247499167919159, -0.0008069931645877659, 0.07709047198295593, -0.00838143564760685, -0.019510706886649132, -0.010018352419137955, 0.039672449231147766, -0.028217975050210953, -0.07585395127534866, -0.1362340897321701, 0.07591814547777176, 0.09382756799459457, -0.008690453134477139, 0.019439471885561943, 0.010210592299699783, -0.07577032595872879, 0.04861726611852646, 0.022610317915678024, -0.01907508634030819, -0.009042199701070786, -0.08233446627855301, 0.01644202508032322, -0.0426647774875164, -0.023533938452601433, 0.024845225736498833, 0.0022729728370904922, 0.01787528023123741, -0.004468485247343779, -0.026583682745695114, 0.023575056344270706, -0.024375615641474724, 0.004249707330018282, 0.017996331676840782, -0.03462690860033035, -0.0792599692940712, 0.031211616471409798, 0.026010841131210327, -0.027465377002954483, 0.006719882134348154, 0.0020857411436736584, 0.01761690340936184, 0.01746492087841034, 0.053649403154850006, -0.09719900786876678, 0.02726726420223713, 0.0041374205611646175, -0.026371505111455917, -0.020569978281855583, 0.01849859207868576, 0.03474188968539238, 0.004058477934449911, -0.02588554471731186, -0.022454923018813133, -0.05139715224504471, -0.07802660018205643, 0.026631709188222885, -0.028420334681868553, -0.03949905186891556, -0.028402356430888176, 0.04028543457388878, -0.02622988633811474, -0.015416868031024933, -0.08897228538990021, -0.006946973968297243, 0.00710170017555356, -0.03887337073683739, -0.02123122848570347, 0.01805717498064041, 0.0344419963657856, -0.04805963113903999, 0.03656536340713501, -0.022134752944111824, 0.00817906204611063, -0.04252343624830246, 0.009770439006388187, -0.01689697988331318, -0.0260008592158556, -0.015728693455457687, -0.012875941582024097, -0.06102177873253822, -0.008011510595679283, -0.03141343593597412, 0.04607613757252693, 0.019290471449494362, -0.05614999681711197, -0.0626102164387703, -0.010851754806935787, -0.04783433675765991, 0.01892949640750885, -0.037196069955825806, -0.029953237622976303, -0.016390573233366013, 0.03903897851705551, 0.01227223314344883, -0.030694490298628807, -0.025610066950321198, -0.041420549154281616, 0.022946758195757866, 0.008837624453008175, 0.02584686502814293, 0.008095208555459976, 0.0430380254983902, 0.00742639834061265, -0.01789223775267601, 0.06770210713148117, 0.004289376083761454, 0.008603089489042759, 0.01378733478486538, 0.03245336934924126, -0.01590084098279476, -0.010305567644536495, -0.011169102974236012, 0.02103716880083084, -0.044015295803546906, -0.003294517984613776, -0.010823548771440983, 0.021978741511702538, -0.0013411757536232471, -0.07058368623256683, -0.04888467118144035, 0.012891210615634918, -0.02317993901669979, 0.02376372180879116, -0.02273913472890854, -0.00690293125808239, -0.016848333179950714, -0.037606850266456604, 0.016563672572374344, 0.05340617150068283, 0.006045289803296328, 0.059975627809762955, -0.002571186050772667, -0.06861039996147156, -0.008420819416642189, 0.01377375703305006, 0.025352496653795242, 0.02028140425682068, -0.0305411908775568, -0.03251797333359718, -0.06120520085096359, -0.014559393748641014, -0.02170858532190323, -0.04539666697382927, -0.004923057742416859, -0.010451139882206917, -0.02956731803715229, 0.05434400588274002, 0.0014316325541585684, 0.0164483729749918, -0.0548328272998333, 0.0035998490639030933, 0.0025368465576320887, 0.019528821110725403, -0.07159475982189178, 0.06815468519926071, 0.02410038933157921, 0.045986633747816086, 0.011254469864070415, 0.021867210045456886, 0.009737428277730942, 0.05949988588690758, -0.04802311584353447, -0.024196499958634377, -0.019624751061201096, -0.015714231878519058, -0.026338843628764153, -0.032651204615831375, -0.023289354518055916, 0.017006704583764076, -0.05780372768640518, 0.013706867583096027, -0.034762755036354065, 0.0052970717661082745, 0.0176913570612669, -0.004919999744743109, -0.05247485637664795, -0.04030724614858627, -0.10258959978818893, -0.00859836395829916, 0.020211149007081985, 0.04474553093314171, -0.0526076965034008, 0.012720085680484772, -0.05081895366311073, -0.035338424146175385, 0.0023963050916790962, -0.030323723331093788, 0.011844326741993427, -0.02357429638504982, 0.007814189419150352, -0.013991127721965313, -0.058796484023332596, 0.07445056736469269, 0.0465429462492466, -0.026994947344064713, 0.006451377645134926, -0.011758445762097836, -0.02837166003882885, 0.035541072487831116, 0.011907235719263554, -0.0052772038616240025, 0.023883866146206856, 0.012279005721211433, 0.011675804853439331, 0.03490255028009415, -0.025815939530730247, 0.04386910796165466, 0.017611755058169365, 0.04958317428827286, 0.039289481937885284, 0.013265370391309261, 0.03610560670495033, 0.005503167863935232, 0.021461468189954758, -0.06844760477542877, 0.013246484100818634, 0.04152173548936844, -0.029613517224788666, -0.01957281492650509, -0.03483524173498154, -0.03825502097606659, -0.020166005939245224, 0.021265221759676933, 0.06129218265414238, -0.04163709282875061, 0.014791393652558327, 0.014529740437865257, 0.010896045714616776, -0.11543422192335129, -0.03360319882631302, -0.05589929223060608, -0.05811789259314537, -0.012332974001765251, 0.014787249267101288, -0.09898144751787186, 0.02594282664358616, -0.0005415517371147871, 0.008792607113718987, -0.03125834837555885, 0.04435426741838455, 0.00942982267588377, 0.000868803181219846, 0.06188846752047539, -0.015446916222572327, -0.07226631790399551, -0.044506099075078964, 0.017528332769870758, 0.039571281522512436, -0.051951903849840164, 0.0032469776924699545, -0.003773163538426161, 0.034786321222782135, -0.009412731043994427, 0.026751253753900528, 0.03839461877942085, 0.05171748623251915, 0.012119683437049389, -0.07094941288232803, 0.06583517789840698, -0.00445381086319685, -0.019545819610357285, -0.03581184521317482, -0.03221912309527397, 0.06569118797779083, -0.0051487949676811695, -0.010263553820550442, 0.019870826974511147, -0.02322455495595932, -0.017076067626476288, -0.005842494312673807, -0.00406220369040966, -0.028368519619107246, -0.00017507618758827448, 0.026795191690325737, -0.010769983753561974, 0.004666486289352179, -0.010733024217188358, 0.0007423970964737236, 0.06672339886426926, 0.02625289559364319, -0.03991442918777466, 0.02290494740009308, 0.019931890070438385, 0.012672273442149162, -0.026643624529242516, -0.00849990826100111, 0.007982770912349224, 0.011553523130714893, 0.01313185878098011, 0.016604015603661537, 0.03154205158352852, -0.08784219622612, -0.05190761759877205, -0.03165704384446144, -0.005474531091749668, 0.04079993814229965, 0.0038400550838559866, 0.04367854446172714, -0.05150669813156128, -0.024722052738070488, 0.019934827461838722, 0.03144526109099388, -0.04412183165550232, 0.018581928685307503, -0.020380990579724312, 0.03142813965678215, 0.029637156054377556, 0.02292359434068203, -0.03589651361107826, 0.034826334565877914, -0.011483040638267994, -0.0017426611157134175, 0.0034471682738512754, 0.02760867029428482, 0.07813266664743423, -0.02380296029150486, -0.038689058274030685, -0.038704123347997665, 0.045501913875341415, -0.0018269248539581895, 0.04165354371070862, 0.0010681857820600271, -0.03636687994003296, -0.04324778541922569, -0.001840935554355383, -0.01632324978709221, -0.05531185492873192, -0.03420332074165344, 0.003457342740148306, -0.01638178899884224, 0.0062800198793411255, -0.011392820626497269, 0.0007934024324640632, -0.01728118024766445, 0.07051656395196915, 0.006142304744571447, 0.0010320268338546157, -0.07756688445806503, -0.01725735329091549, -0.017777113243937492, 0.025545917451381683, 0.03787548840045929, 0.0203388798981905, 0.01669018343091011, -0.0009158957982435822, -0.05879148468375206, 0.026536772027611732, 0.043445173650979996, -0.020170288160443306, -0.04645369201898575, -0.03924264758825302, -0.008544772863388062, -0.059880416840314865, -0.0038524868432432413, 0.05935370549559593, 0.02478773333132267, -0.036441951990127563, 0.03433588519692421, 0.0608387216925621, -0.025580616667866707, 0.03542158752679825, -0.08336429297924042, -0.014501698315143585, -0.04314250126481056, 0.0010071329306811094, 0.01394415833055973, -0.041038889437913895, 0.05676395073533058, 0.03354688733816147, 0.03245168179273605, -0.014439379796385765, 0.024018868803977966, -0.03283117339015007, -0.014726938679814339, 0.020077310502529144, 0.052366703748703, 0.018686365336179733, -0.030141469091176987, -0.06950796395540237, 0.02743900567293167, -0.044662877917289734, -0.027372850105166435, 0.02613779716193676, 0.008398720063269138, 0.014098933897912502, 0.00506135867908597, 0.03247535601258278, -0.01905762031674385, -0.019495641812682152, 0.021818963810801506, 0.015862062573432922, 0.03693776950240135, 0.014613614417612553, 0.053203411400318146, 0.033699098974466324, 0.03218269348144531, 0.08045617491006851, -0.0598096065223217, -0.05742032080888748, -0.03999164700508118, 0.033143650740385056, 0.004230685066431761, 0.06087212264537811, 0.024544531479477882, 0.019837401807308197, 0.006001709029078484, -0.031885817646980286, -0.030693262815475464, 0.007243372034281492, 0.022703975439071655, -0.017832132056355476, 0.026842646300792694, 0.06014237552881241, 0.0007703949231654406, 0.01269793976098299, -0.030843039974570274, 0.03642132133245468, -0.008549673482775688, -0.006215762812644243, -0.05973336845636368, 0.04635118693113327, 0.03762282058596611, 0.05289364978671074, 0.012984080240130424, 0.06197143346071243, -0.00251937797293067, -0.04079684242606163, 0.006324432324618101, -0.06220356747508049, 0.05567621812224388, -0.0270114466547966, 0.04752492904663086, -0.03955288231372833, -0.023822743445634842, 0.011177146807312965, -0.0002126664185198024, -0.015335524454712868, -0.018749145790934563, -0.01252884790301323, 0.017657190561294556, -0.0018241048092022538, -0.04749300330877304, -0.029716921970248222, 0.05201757326722145, 0.013973613269627094, 0.05358352139592171, -0.005169920157641172, 0.06108623743057251, -0.00034020538441836834, 0.00204732408747077, 0.022032570093870163, 0.009585895575582981, 0.007635426241904497, 0.010191744193434715, -0.0016849159728735685, 0.039626624435186386, -0.004662736319005489, -0.03499935194849968, 0.02045140229165554, 0.03854590654373169, -0.01136835291981697, 0.11801902204751968, 0.027295632287859917, -0.03454121947288513, -0.06620489805936813, -0.022455863654613495, -0.036504313349723816, -0.027751805260777473, 0.02426913008093834, -0.010416404344141483, -0.03599536791443825, -0.023112168535590172, 0.024780815467238426, -0.04206731915473938, 0.04737454652786255, 0.010679048486053944, 0.045824650675058365, -0.012001056224107742, 0.010149226523935795, 0.02402861788868904, 0.010881604626774788, -0.02032933197915554, 0.03122020699083805, 0.045521169900894165, 0.0019749668426811695, 0.00021772073523607105, 0.049741219729185104, -0.0032710381783545017, -0.02781662903726101, 0.01512980554252863, 0.06713394075632095, -0.0158261526376009, 0.02157570794224739, 0.015458326786756516, 0.06363721191883087, 0.012749752029776573, -0.026469390839338303, 0.009748454205691814, 0.005470410920679569, -0.031643062829971313, 0.036677468568086624, 0.07205954939126968, -0.050301443785429, 0.0030132040847092867, 0.03684893995523453, -0.027988746762275696, 0.047528158873319626, 0.021805569529533386, -0.034064192324876785, 0.007725028786808252, 0.0008075462537817657, 0.005813617259263992, -0.014014477841556072, -0.027894562110304832, 0.0014065718278288841, -0.035173263400793076, -0.02289736084640026, -0.06290272623300552, -0.022646894678473473, -0.041230879724025726, 0.06479673087596893, 0.0555911622941494, -0.040556855499744415, 0.007456792518496513, -0.04380102455615997, -0.023841260001063347, -0.04093717783689499, 0.009272179566323757, 0.00582896126434207, 0.0016683698631823063, 0.08151273429393768, 0.020490366965532303, 0.0024195886217057705, 0.006366673391312361, -0.026029929518699646, 0.015564830042421818, -0.05851592868566513, 0.006237562745809555, -0.05297559127211571, 0.019300058484077454, -0.025418123230338097, -0.026909632608294487, -0.024857250973582268, -0.006227914243936539, 0.036833859980106354, 0.011286056600511074, -0.003237767145037651, 0.01138349436223507, -0.016271600499749184, 0.01307633239775896, -0.007788393180817366, -0.06915568560361862, 0.005114726722240448, 0.040353816002607346, 0.04037889093160629, 0.023325007408857346, -0.06489475816488266, 0.002100869780406356, 0.010500557720661163, -0.027305060997605324, -0.03512360528111458, 0.04678768664598465, -0.024756107479333878, 0.04770822823047638, -0.012653275392949581, 0.04199439659714699, -0.03723035007715225, 0.021079018712043762, -0.040204621851444244, -0.055284418165683746, 0.026441583409905434, -0.018350470811128616, -0.04611121490597725, -0.03347180783748627, 0.01706829108297825, -0.010559997521340847, -0.019669044762849808, -0.01892927847802639, -0.040444862097501755, 0.02622443437576294, 0.046169232577085495, -0.04466930776834488, -0.006864430382847786, 0.024980543181300163, -0.00559600442647934, 0.05515807121992111, -0.029814261943101883, -0.027459153905510902, 0.050755176693201065, -0.02899012714624405, -0.02816769666969776, 0.010095490142703056, -0.0017784872325137258, -0.03370315209031105, 0.02437799796462059, -0.0002741724601946771, -0.013288548216223717, -0.021402321755886078, 0.021412288770079613, -0.0025492662098258734, 0.03122108243405819, -0.012782253324985504, 0.01649075746536255, -0.008483967743813992, -0.030046774074435234, 0.014040936715900898, -0.020978521555662155, 0.0903482437133789, -0.026532525196671486, 0.036920785903930664, 0.053320810198783875, 0.0033778005745261908, -0.03507322445511818, -0.028353866189718246, -0.054508112370967865, 0.0011092553613707423, 0.033273614943027496, 0.013821336440742016, 0.031121917068958282, 0.011944682337343693, 0.018730593845248222, -0.014167198911309242, -0.017753787338733673, 0.030909964814782143, 0.062414612621068954, -0.01106966007500887, 0.0007920278003439307, -0.0031770209316164255, 0.010590525344014168, -0.015446615405380726, 0.028239797800779343, 0.0732949748635292, -0.0019514415180310607, -0.038540735840797424, 0.01942184753715992, 0.048093531280756, 0.06383849680423737, 0.03807168826460838, -0.08535566180944443, 0.010056694969534874, -0.03838665783405304, 0.025605836883187294, -0.0011507237795740366, 0.024316413328051567, 0.01178177259862423, 0.016260962933301926, 0.009767747484147549, -0.007292686961591244, 0.027287857607007027, -0.042929600924253464, -0.01323598064482212, -0.02688555233180523, 0.03531723842024803, 0.008915160782635212, -0.004012776538729668, -0.05119200795888901, -0.015749920159578323, 0.021718118339776993, 0.008989322930574417, -0.06974360346794128, 0.014973211102187634, -0.011397730559110641, -0.07624229043722153, 0.017569998279213905, 0.060562871396541595, -0.0028631435707211494, 0.05745212733745575, -0.022273819893598557, 0.04074757173657417, -0.02943744696676731, 0.03616159036755562, 0.031222470104694366, -0.010470662266016006, 0.04254848137497902, -0.015562483109533787, 0.027763474732637405, -0.07111009955406189, 0.021353261545300484, 0.031004874035716057, -0.022343460470438004]\n"
     ]
    }
   ],
   "source": [
    "response = client.embeddings.create (\n",
    "\n",
    "    input=\"æ‚¨çš„æ–‡æœ¬å­—ç¬¦ä¸²åœ¨è¿™é‡Œ\",\n",
    "    model=\"text-embedding-004\"\n",
    ")\n",
    "print (response.data [0].embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
