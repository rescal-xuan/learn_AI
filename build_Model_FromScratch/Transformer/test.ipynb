{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入序列的位置编码:\n",
      "torch.Size([5, 100, 512])\n",
      "输出序列的位置编码:\n",
      "torch.Size([5, 100, 512])\n"
     ]
    }
   ],
   "source": [
    "from model import PositionalEncoding\n",
    "# 位置编码示例用法\n",
    "\n",
    "d_model = 512\n",
    "max_len = 100\n",
    "num_heads = 8\n",
    "# 位置编码\n",
    "pos_encoder = PositionalEncoding(max_len,d_model)\n",
    "\n",
    "# 示例输入序列\n",
    "input_sequence = torch.randn(5, max_len, d_model)\n",
    "print(\"输入序列的位置编码:\")\n",
    "print(input_sequence.shape)\n",
    "# 应用位置编码\n",
    "output_sequence = pos_encoder(input_sequence)\n",
    "print(\"输出序列的位置编码:\")\n",
    "print(output_sequence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_output shape: torch.Size([5, 100, 512])\n"
     ]
    }
   ],
   "source": [
    "# 多头注意力机制示例用法\n",
    "from model import MutiHeadAttention\n",
    "d_model = 512\n",
    "max_len = 100\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "# 多头注意力\n",
    "multihead_attn = MutiHeadAttention(num_heads,d_model)\n",
    "\n",
    "# 示例输入序列\n",
    "input_sequence = torch.randn(5, max_len, d_model)\n",
    "\n",
    "# 多头注意力\n",
    "attention_output= multihead_attn(input_sequence, input_sequence, input_sequence)\n",
    "print(\"attention_output shape:\", attention_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_sequence torch.Size([5, 100, 512])\n",
      "output_ff torch.Size([5, 100, 512])\n"
     ]
    }
   ],
   "source": [
    "# 前馈示例用法\n",
    "from model  import FeedForward\n",
    "d_model = 512\n",
    "max_len = 100\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "\n",
    "# 多头注意力\n",
    "multihead_attn = MutiHeadAttention(num_heads,d_model)\n",
    "\n",
    "# 前馈网络\n",
    "ff_network = FeedForward(d_model, d_ff)\n",
    "\n",
    "# 示例输入序列\n",
    "input_sequence = torch.randn(5, max_len, d_model)\n",
    "\n",
    "# 多头注意力\n",
    "attention_output= multihead_attn(input_sequence, input_sequence, input_sequence)\n",
    "\n",
    "# 前馈网络\n",
    "output_ff = ff_network(attention_output)\n",
    "print('input_sequence',input_sequence.shape)\n",
    "print(\"output_ff\", output_ff.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder output shape: torch.Size([1, 100, 512])\n"
     ]
    }
   ],
   "source": [
    "# 定义DecoderLayer的参数\n",
    "from  model  import encodelayer\n",
    "d_model = 512\n",
    "max_len = 100\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "\n",
    "\n",
    "# 多头注意力\n",
    "encoder_layer = encodelayer(num_heads,d_model,  d_ff, 0.1)\n",
    "\n",
    "# 示例输入序列\n",
    "input_sequence = torch.randn(1, max_len, d_model)\n",
    "\n",
    "# 多头注意力\n",
    "encoder_output= encoder_layer(input_sequence, None)\n",
    "print(\"encoder output shape:\", encoder_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 100, 512])\n"
     ]
    }
   ],
   "source": [
    "# 定义DecoderLayer的参数\n",
    "from  model  import decodelayer\n",
    "d_model = 512  # 模型的维度\n",
    "num_heads = 8  # 注意力头的数量\n",
    "d_ff = 2048    # 前馈网络的维度\n",
    "dropout = 0.1  # 丢弃概率\n",
    "batch_size = 1 # 批量大小\n",
    "max_len = 100  # 序列的最大长度\n",
    "\n",
    "# 定义DecoderLayer实例\n",
    "decoder_layer = decodelayer(num_heads,d_model,  d_ff, dropout)\n",
    "\n",
    "\n",
    "src_mask = torch.rand(batch_size, max_len, max_len) > 0.5\n",
    "tgt_mask = torch.tril(torch.ones(max_len, max_len)).unsqueeze(0) == 0\n",
    "\n",
    "# 将输入张量传递到DecoderLayer\n",
    "output = decoder_layer(input_sequence, encoder_output, src_mask, tgt_mask)\n",
    "\n",
    "# 输出形状\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0834, -0.4275, -0.5930,  ..., -0.3214, -0.0957, -0.3598],\n",
      "         [-0.6972, -0.2875,  0.4555,  ...,  0.0044, -1.4032, -0.2224],\n",
      "         [ 0.1854, -0.3504,  0.1302,  ...,  0.7794, -0.0074,  0.7875],\n",
      "         ...,\n",
      "         [ 0.3470, -1.0003,  0.0825,  ...,  0.7346,  0.1772, -0.2238],\n",
      "         [-0.1555, -0.3822, -0.8029,  ...,  0.1747,  1.0066, -0.0496],\n",
      "         [-0.6953,  1.3396, -0.1791,  ...,  0.0960,  0.6512,  0.0535]],\n",
      "\n",
      "        [[-0.0422, -0.6675, -0.7893,  ..., -0.2648,  0.3255, -0.4737],\n",
      "         [-0.3078, -0.2277,  0.1688,  ...,  0.9857, -0.4644, -0.6475],\n",
      "         [-0.4555, -0.7379,  0.0341,  ..., -1.2845, -0.3576, -0.7086],\n",
      "         ...,\n",
      "         [ 0.3605, -0.5538, -0.1183,  ...,  0.7157,  0.5060, -0.1151],\n",
      "         [-0.7584,  0.6960,  0.1792,  ...,  0.0642,  1.2483, -0.0780],\n",
      "         [ 1.4671, -0.2962,  0.4607,  ...,  0.1683,  0.0286, -0.3764]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "torch.Size([2, 100, 21129])\n"
     ]
    }
   ],
   "source": [
    "# 示例用法\n",
    "src_vocab_size = 500\n",
    "tgt_vocab_size = 500\n",
    "from   transformers  import  AutoTokenizer\n",
    "from  model  import Transformer\n",
    "tokenizer = AutoTokenizer.from_pretrained('./model_/gpt2_chinese')\n",
    "src_vocab_size = len(tokenizer)\n",
    "tgt_vocab_size = len(tokenizer)\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "max_len = 100\n",
    "dropout = 0.1\n",
    "\n",
    "model =Transformer(src_vocab_size,tgt_vocab_size,num_heads,d_model,d_ff,num_layers,max_len,dropout)\n",
    "\n",
    "src_data = torch.randint(1, src_vocab_size, (2, max_len))  # (batch_size, seq_length)\n",
    "tgt_data = torch.randint(1, tgt_vocab_size, (2, max_len))  # (batch_size, seq_length)\n",
    "output = model(src_data,tgt_data)\n",
    "print(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21129 21129\n",
      "tensor([[ 101, 8701, 8572,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [ 101, 9510, 8995, 8357,  102,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]]) tensor([[ 101,  872, 1962,  686, 4518,  102,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [ 101,  872, 1962, 1408,  102,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]])\n",
      "tensor([[[ 8.9295e-01, -1.4452e-01, -3.6400e-02,  ..., -4.1150e-01,\n",
      "           3.3028e-01, -1.8038e-01],\n",
      "         [ 3.2509e-01,  1.2690e+00, -1.2035e-01,  ..., -4.2629e-01,\n",
      "           1.2011e+00, -1.9148e-01],\n",
      "         [ 1.9627e-02, -5.9843e-01,  1.1350e-01,  ...,  8.5012e-01,\n",
      "           6.3903e-01, -9.3481e-01],\n",
      "         ...,\n",
      "         [ 1.7434e-01, -4.0850e-01,  4.0380e-01,  ...,  4.6439e-01,\n",
      "          -1.1731e-01, -9.0197e-02],\n",
      "         [ 1.3259e+00,  3.9146e-02, -4.3109e-01,  ..., -9.2198e-02,\n",
      "           6.1943e-01, -8.1215e-02],\n",
      "         [ 5.1536e-01, -1.1776e-01, -3.1788e-02,  ...,  1.0201e+00,\n",
      "           9.9882e-02,  7.3660e-01]],\n",
      "\n",
      "        [[ 7.3026e-01,  1.7188e-01,  5.3426e-01,  ...,  7.2757e-02,\n",
      "           7.8770e-01, -5.6008e-01],\n",
      "         [-5.6162e-01,  5.0298e-01,  4.3227e-01,  ...,  2.2113e-04,\n",
      "          -3.4556e-01, -1.5439e-02],\n",
      "         [-6.6552e-01,  5.7949e-01, -9.4730e-02,  ...,  6.9279e-01,\n",
      "           1.1102e+00, -8.5633e-01],\n",
      "         ...,\n",
      "         [ 1.3974e+00, -1.5487e-01, -1.5473e-01,  ...,  2.7503e-01,\n",
      "           1.2421e+00, -7.3734e-01],\n",
      "         [ 2.7484e-01, -1.2673e-01,  5.1955e-02,  ...,  4.6448e-01,\n",
      "           5.1288e-02, -8.9055e-01],\n",
      "         [ 7.5491e-01,  3.6569e-01, -5.0092e-01,  ..., -2.1907e-01,\n",
      "          -1.9467e-01,  6.3057e-01]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "src_texts = [\"hello world\", \"how are you\"]  # 真实的源文本\n",
    "tgt_texts = [\"你好世界\", \"你好吗\"]  # 真实的目标文本\n",
    "\n",
    "# 分词和填充\n",
    "src_encoded = tokenizer(src_texts, padding=\"max_length\", truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "tgt_encoded = tokenizer(tgt_texts, padding=\"max_length\", truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "\n",
    "src_data = src_encoded['input_ids'] #  (batch_size, seq_len)\n",
    "tgt_data = tgt_encoded['input_ids'] #  (batch_size, seq_len)\n",
    "\n",
    "# 添加 <CLS>\n",
    "cls_tokens = torch.full((src_data.shape[0],1), tokenizer.cls_token_id, dtype=torch.long) # create <cls>\n",
    "tgt_input_data = torch.cat([cls_tokens, tgt_data[:, :-1]],dim=-1) # 在目标数据的开头添加cls\n",
    "# 准备 label 数据\n",
    "tgt_labels = tgt_data[:,1:] #  目标数据偏移一个位置，作为 label\n",
    "\n",
    "print(src_vocab_size,tgt_vocab_size )\n",
    "# 调用模型\n",
    "print(src_data,tgt_data)\n",
    "output = model(src_data,tgt_data)\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
